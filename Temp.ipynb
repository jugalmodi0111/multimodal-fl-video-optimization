{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c56af44",
   "metadata": {},
   "source": [
    "Starting: *Design optimal cell placement strategy* (3/4)\n",
    "\n",
    "# ğŸ¯ **STREAMLINED INTEGRATION STRATEGY: VideoActionEnvironment in Natural Flow**\n",
    "\n",
    "## **ğŸ“‹ REVISED INTEGRATION PLAN**\n",
    "\n",
    "Instead of adding cells at the end, I'll **weave the new Deep RL system into the existing structure** for a natural top-to-bottom workflow:\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ—ï¸ OPTIMAL CELL PLACEMENT (One-liner per module)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f97466",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ STREAMLINED NOTEBOOK STRUCTURE (49 Cells Total)                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 1: SETUP (Cells 1-5) âœ“ UNCHANGED                         â”‚\n",
    "â”‚   â””â”€ Device detection, imports, synthetic data                  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 2: KINETICS DATA (Cells 6-14) âœ“ UNCHANGED                â”‚\n",
    "â”‚   â””â”€ 693D features, train/test split, creates X_train/X_test   â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 15: VideoActionEnvironment Class                 â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: Gym environment for video streaming decisions  â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚   â†“ uses Kinetics features from Cell 14                         â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 16: Create Video Clients                         â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: Wrap each client's data into video envs        â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚   â†“ creates video_clients[]                                     â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 3: ANALYSIS (Old Cells 15-17 â†’ New Cells 17-19)          â”‚\n",
    "â”‚   â””â”€ Statistics, visualizations, partition analysis             â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 4: EXISTING FL ENVIRONMENTS (Old 18-28 â†’ New 20-30)      â”‚\n",
    "â”‚   â””â”€ GNN, ONNX, MLP-based federated aggregation                 â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 31: Federated DRL Training Function              â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: FedAvg for video policies with PPO/SAC/TD3     â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚   â†“ defines federated_drl_train()                               â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 5: RL TRAINING (Old Cells 29-35 â†’ New Cells 32-38)       â”‚\n",
    "â”‚   â””â”€ Existing agent training, configurations                    â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 39: Execute Video DRL Training                   â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: Run 10 federated rounds on video clients       â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚   â†“ produces federated_results                                  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 40: DRL Ensemble Evaluation                      â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: Meta-controller combining local video policies â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚   â†“ creates ensemble, comparison_df                             â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ Phase 6: EVALUATION (Old Cells 36-44 â†’ New Cells 41-49)        â”‚\n",
    "â”‚   â””â”€ Existing results analysis, plots, saving                   â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚ â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚\n",
    "â”‚ â•‘ NEW Cell 50: Video DRL Monitoring Dashboard               â•‘  â”‚\n",
    "â”‚ â•‘ One-liner: Live plots for video streaming performance     â•‘  â”‚\n",
    "â”‚ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d3d12",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“Š INSERTION POINTS DETAILED**\n",
    "\n",
    "### **ğŸ¯ Module 1: VideoActionEnvironment (Insert after Cell 14)**\n",
    "\n",
    "**Position:** New Cell 15  \n",
    "**Why here:** Right after Kinetics data generation, before analysis  \n",
    "**Dependencies met:** X_train/X_test available, gymnasium imported  \n",
    "**One-liner:** Custom Gym environment for video streaming with action space [skip_frames, bitrate, prefetch]\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ¯ Module 2: Video Clients (Insert after Cell 15)**\n",
    "\n",
    "**Position:** New Cell 16  \n",
    "**Why here:** Immediately after environment class definition  \n",
    "**Dependencies met:** VideoActionEnvironment class, clients[] list  \n",
    "**One-liner:** Creates 5 video environments wrapping each client's Kinetics features\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ¯ Module 3: Federated DRL Function (Insert after Cell 30)**\n",
    "\n",
    "**Position:** New Cell 31  \n",
    "**Why here:** After all environment definitions, before training execution  \n",
    "**Dependencies met:** video_clients[], PPO/SAC/TD3 imported  \n",
    "**One-liner:** FedAvg aggregation function for video streaming policies with 10-round training loop\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ¯ Module 4: Execute Training (Insert after Cell 38)**\n",
    "\n",
    "**Position:** New Cell 39  \n",
    "**Why here:** Among existing RL training cells, parallel to other experiments  \n",
    "**Dependencies met:** federated_drl_train() defined, video_clients ready  \n",
    "**One-liner:** Runs federated video DRL training (5-10min) producing local_agents and global_policy\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ¯ Module 5: Ensemble Evaluation (Insert after Cell 39)**\n",
    "\n",
    "**Position:** New Cell 40  \n",
    "**Why here:** Right after training, before general evaluation phase  \n",
    "**Dependencies met:** federated_results available, X_test ready  \n",
    "**One-liner:** Meta-controller ensemble combining client policies with voting strategy and test set evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ¯ Module 6: Live Dashboard (Insert at end)**\n",
    "\n",
    "**Position:** New Cell 50  \n",
    "**Why here:** Final visualization after all results collected  \n",
    "**Dependencies met:** federated_results, existing plots complete  \n",
    "**One-liner:** 4-panel dashboard showing reward curves, action distributions, and convergence metrics\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ”„ EXECUTION FLOW (Natural Top-to-Bottom)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0bf70",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "User runs notebook sequentially:\n",
    "\n",
    "Cells 1-5    â†’ Setup âœ“\n",
    "Cells 6-14   â†’ Generate Kinetics data âœ“\n",
    "Cell 15 NEW  â†’ Define VideoActionEnvironment âœ“\n",
    "Cell 16 NEW  â†’ Create video_clients âœ“\n",
    "Cells 17-30  â†’ Analysis + existing FL environments âœ“\n",
    "Cell 31 NEW  â†’ Define federated_drl_train() âœ“\n",
    "Cells 32-38  â†’ Existing RL training âœ“\n",
    "Cell 39 NEW  â†’ Execute video DRL training (WAIT 5-10min) âœ“\n",
    "Cell 40 NEW  â†’ Evaluate ensemble âœ“\n",
    "Cells 41-49  â†’ Existing results/plots âœ“\n",
    "Cell 50 NEW  â†’ Video DRL dashboard âœ“\n",
    "\n",
    "Total: 50 cells, 6 new cells integrated naturally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e1a14",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **âœ… ADVANTAGES OF THIS APPROACH**\n",
    "\n",
    "1. **Natural Flow:** Video environment appears right after data generation\n",
    "2. **Parallel Experiments:** Video DRL runs alongside existing FL-RL experiments\n",
    "3. **No Disruption:** Existing cells renumbered but unchanged\n",
    "4. **Incremental Testing:** Can run up to any point and stop\n",
    "5. **Clean Narrative:** Story flows from data â†’ environments â†’ training â†’ evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“ DETAILED INSERTION SPECIFICATION**\n",
    "\n",
    "### **Insertion Point 1: After Cell 14 (Kinetics Split)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT Cell 14 ends with:\n",
    "# âœ… X_train, y_train created\n",
    "# âœ… X_test, y_test created\n",
    "\n",
    "# INSERT NEW Cell 15: VideoActionEnvironment\n",
    "# - Defines class\n",
    "# - Action space: MultiDiscrete([5, 4, 3])\n",
    "# - Observation space: Box(693,)\n",
    "# - Reward: quality - latency + smoothness\n",
    "# - ~70 lines of code\n",
    "\n",
    "# INSERT NEW Cell 16: Create Video Clients  \n",
    "# - for client in clients: create VideoActionEnvironment\n",
    "# - video_clients = [env1, env2, env3, env4, env5]\n",
    "# - ~30 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ded43e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Insertion Point 2: After Cell 30 (All Environments Defined)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT Cell 30 ends with:\n",
    "# âœ… All FL environments defined (ONNX, MLP, GNN)\n",
    "\n",
    "# INSERT NEW Cell 31: Federated DRL Training Function\n",
    "# - def federated_drl_train(video_clients, n_rounds=10, algorithm='PPO')\n",
    "# - Implements FedAvg for policies\n",
    "# - Returns federated_results dict\n",
    "# - ~80 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169c686",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Insertion Point 3: After Cell 38 (Among Training Cells)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef559d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT Cells 32-38:\n",
    "# âœ… PPO config, SAC config, TD3 config\n",
    "# âœ… Individual agent training\n",
    "\n",
    "# INSERT NEW Cell 39: Execute Video DRL Training\n",
    "# - federated_results = federated_drl_train(video_clients)\n",
    "# - Progress bars for 10 rounds\n",
    "# - Saves metrics to federated_results\n",
    "# - ~40 lines of code\n",
    "\n",
    "# INSERT NEW Cell 40: Ensemble Evaluation\n",
    "# - class DRLEnsemble with voting\n",
    "# - Test on X_test\n",
    "# - comparison_df with all agents\n",
    "# - ~60 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d509c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Insertion Point 4: At End (After Cell 49)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT Cell 49 ends evaluation\n",
    "\n",
    "# INSERT NEW Cell 50: Video DRL Dashboard\n",
    "# - 4-panel matplotlib figure\n",
    "# - Reward curves, action heatmap, convergence\n",
    "# - Save to drl_outputs/\n",
    "# - ~50 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3daf4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ¯ IMPLEMENTATION STRATEGY**\n",
    "\n",
    "**Step 1:** Insert Cells 15-16 (VideoActionEnvironment + clients)  \n",
    "**Step 2:** Renumber old Cells 15-44 â†’ new Cells 17-46  \n",
    "**Step 3:** Insert Cell 31 (federated_drl_train function)  \n",
    "**Step 4:** Renumber old Cells 29-46 â†’ new Cells 32-49  \n",
    "**Step 5:** Insert Cells 39-40 (execution + ensemble)  \n",
    "**Step 6:** Insert Cell 50 (dashboard)  \n",
    "\n",
    "**Total cells:** 44 existing + 6 new = **50 cells**\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“‹ ONE-LINER SUMMARY FOR EACH NEW CELL**\n",
    "\n",
    "| Cell | One-Liner Description |\n",
    "|------|----------------------|\n",
    "| **15** | VideoActionEnvironment: Gym env with actions [skip, bitrate, prefetch] and quality-latency reward |\n",
    "| **16** | Create 5 video streaming environments wrapping each federated client's Kinetics features |\n",
    "| **31** | federated_drl_train(): FedAvg aggregation for video policies with configurable PPO/SAC/TD3 |\n",
    "| **39** | Execute 10-round federated video DRL training with progress tracking (5-10min runtime) |\n",
    "| **40** | DRLEnsemble: Meta-controller combining client policies via voting with test set evaluation |\n",
    "| **50** | Live monitoring dashboard: 4-panel plot showing rewards, actions, and convergence |\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸš€ READY FOR IMPLEMENTATION**\n",
    "\n",
    "**Confirm with:**  \n",
    "âœ… **\"Approved - integrate into flow\"** â†’ I'll insert cells at optimal positions  \n",
    "âœ… **\"Show me Cell 15 first\"** â†’ I'll create just the first new cell as preview  \n",
    "âœ… **\"Modify placement\"** â†’ Suggest different insertion points  \n",
    "\n",
    "Once approved, I will:\n",
    "1. Create all 6 new cells with proper placement markers\n",
    "2. Provide clear instructions for where to insert each\n",
    "3. Include verification code for each cell\n",
    "4. Add inline comments explaining dependencies\n",
    "\n",
    "**Ready to proceed?** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595f4a0",
   "metadata": {},
   "source": [
    "Retrieving Notebook summary.\n",
    "\n",
    "Created 4 todos\n",
    "\n",
    "Starting: *Map dependencies and prerequisites* (2/4)\n",
    "\n",
    "# ğŸ“˜ **IN-DEPTH INTEGRATION PLAN: VideoActionEnvironment + Deep RL**\n",
    "\n",
    "## **EXECUTIVE SUMMARY**\n",
    "\n",
    "This plan details how to seamlessly integrate a **video-specific Deep RL system** into your existing FL-RL notebook without disrupting current functionality. The integration adds **5 new cells** (45-49) and **3 utility files**, creating a parallel video streaming application while preserving your existing federated aggregation system.\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 1: CURRENT STATE ANALYSIS**\n",
    "\n",
    "### **ğŸ“Š Existing Notebook Architecture (44 Cells)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250faa9f",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ CURRENT SYSTEM (Cells 1-44)                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Phase 1: Setup (Cells 1-5)                                  â”‚\n",
    "â”‚   â”œâ”€ Cell 1: PyTorch + SB3 + Data generation               â”‚\n",
    "â”‚   â”œâ”€ Cells 2-4: Dependencies (PyG, ONNX)                   â”‚\n",
    "â”‚   â””â”€ Cell 5: Device selection                               â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚ Phase 2: Kinetics Data (Cells 6-14)                        â”‚\n",
    "â”‚   â”œâ”€ Cell 12-13: 693D features (pose+temporal+velocity)    â”‚\n",
    "â”‚   â”œâ”€ Cell 14: Train/test split â†’ X_train, X_test           â”‚\n",
    "â”‚   â””â”€ Creates: clients[] with non-IID partitions            â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚ Phase 3: Existing FL-RL (Cells 15-44)                      â”‚\n",
    "â”‚   â”œâ”€ Cell 32: FederatedAggregationEnvMLP                   â”‚\n",
    "â”‚   â”œâ”€ Cells 33-36: PPO/SAC/TD3 training                     â”‚\n",
    "â”‚   â””â”€ Cells 37-44: Results & visualization                   â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚ **Output Variables Available:**                             â”‚\n",
    "â”‚   â€¢ X_train, y_train, X_test, y_test (Kinetics)           â”‚\n",
    "â”‚   â€¢ clients[] (5 FederatedClientMLP objects)               â”‚\n",
    "â”‚   â€¢ n_features = 693                                        â”‚\n",
    "â”‚   â€¢ n_classes = 10                                          â”‚\n",
    "â”‚   â€¢ DEVICE = torch.device (MPS/CUDA/CPU)                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a4d20",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **ğŸ”— Key Integration Points**\n",
    "\n",
    "| Variable | Source Cell | Type | Used By New Cells |\n",
    "|----------|-------------|------|-------------------|\n",
    "| `X_train` | Cell 14 | np.ndarray (140, 693) | Cell 46 (client envs) |\n",
    "| `X_test` | Cell 14 | np.ndarray (60, 693) | Cell 48 (evaluation) |\n",
    "| `y_train` | Cell 14 | np.ndarray (140,) | Cell 46 |\n",
    "| `y_test` | Cell 14 | np.ndarray (60,) | Cell 48 |\n",
    "| `clients` | Cell 1 | List[FederatedClientMLP] | Cell 46 (data extraction) |\n",
    "| `DEVICE` | Cell 1 | torch.device | Cell 47 (GPU training) |\n",
    "| `n_features` | Cell 12 | int = 693 | Cell 45 (env config) |\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 2: INTEGRATION ARCHITECTURE**\n",
    "\n",
    "### **ğŸ—ï¸ New System Design (Cells 45-49)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f139945",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ NEW VIDEO DRL SYSTEM (Cells 45-49)                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Cell 45: ğŸ“¦ VideoActionEnvironment                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ class VideoActionEnvironment(gym.Env):     â”‚            â”‚\n",
    "â”‚  â”‚   State: Kinetics features (693D)          â”‚            â”‚\n",
    "â”‚  â”‚   Action: [skip_frames, bitrate, prefetch] â”‚            â”‚\n",
    "â”‚  â”‚   Reward: quality - latency + smoothness   â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚         â†“ uses                                              â”‚\n",
    "â”‚  Cell 46: ğŸ¬ Create Video Clients                          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ video_clients = []                          â”‚            â”‚\n",
    "â”‚  â”‚ for each client in clients:                â”‚            â”‚\n",
    "â”‚  â”‚   env = VideoActionEnvironment(            â”‚            â”‚\n",
    "â”‚  â”‚     video_features=client.Xlocal           â”‚            â”‚\n",
    "â”‚  â”‚   )                                         â”‚            â”‚\n",
    "â”‚  â”‚   video_clients.append(env)                â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚         â†“ trains                                            â”‚\n",
    "â”‚  Cell 47: ğŸ¤– Federated DRL Training                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ for round in range(10):                    â”‚            â”‚\n",
    "â”‚  â”‚   local_policies = []                      â”‚            â”‚\n",
    "â”‚  â”‚   for env in video_clients:                â”‚            â”‚\n",
    "â”‚  â”‚     agent = PPO('MlpPolicy', env)          â”‚            â”‚\n",
    "â”‚  â”‚     agent.learn(5000 steps)                â”‚            â”‚\n",
    "â”‚  â”‚     local_policies.append(agent.policy)    â”‚            â”‚\n",
    "â”‚  â”‚   global_policy = fedavg(local_policies)   â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚         â†“ evaluates                                         â”‚\n",
    "â”‚  Cell 48: ğŸ“Š Ensemble Evaluation                           â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ ensemble = DRLEnsemble(local_policies)     â”‚            â”‚\n",
    "â”‚  â”‚ test_env = VideoActionEnvironment(X_test)  â”‚            â”‚\n",
    "â”‚  â”‚ rewards = evaluate(ensemble, test_env)     â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚         â†“ visualizes                                        â”‚\n",
    "â”‚  Cell 49: ğŸ“ˆ Live Monitoring Dashboard                     â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ Plot reward curves in real-time            â”‚            â”‚\n",
    "â”‚  â”‚ Display action distributions               â”‚            â”‚\n",
    "â”‚  â”‚ Show federated convergence                 â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a0e32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 3: DETAILED CELL-BY-CELL SPECIFICATION**\n",
    "\n",
    "### **ğŸ“ Cell 45: VideoActionEnvironment Definition**\n",
    "\n",
    "**Purpose:** Create Gym environment for video streaming decisions\n",
    "\n",
    "**Dependencies:**\n",
    "- âœ… `gymnasium` (already imported in Cell 1)\n",
    "- âœ… `numpy` (already imported)\n",
    "- âœ… No new variables needed\n",
    "\n",
    "**Input Variables:** None (pure class definition)\n",
    "\n",
    "**Output Variables:**\n",
    "- `VideoActionEnvironment` (class)\n",
    "\n",
    "**Code Structure:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e5887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import statements (5 lines)\n",
    "# 2. Class definition (60 lines)\n",
    "#    - __init__: Configure action/observation spaces\n",
    "#    - reset: Initialize episode\n",
    "#    - step: Execute action, compute reward\n",
    "#    - _compute_reward: Quality-latency tradeoff\n",
    "# 3. Test instantiation (10 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fc64f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Estimated Runtime:** <0.5 seconds\n",
    "\n",
    "**Verification Check:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941397d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running Cell 45:\n",
    "test_env = VideoActionEnvironment(np.random.rand(100, 693))\n",
    "obs, info = test_env.reset()\n",
    "assert obs.shape == (693,)\n",
    "print(\"âœ… Cell 45 verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407a90a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“ Cell 46: Create Video-Based Federated Clients**\n",
    "\n",
    "**Purpose:** Wrap each client's data into video environments\n",
    "\n",
    "**Dependencies:**\n",
    "- âœ… Requires Cell 45 (VideoActionEnvironment)\n",
    "- âœ… Requires Cell 1 (clients list)\n",
    "- âœ… Requires Cell 14 (X_train, y_train)\n",
    "\n",
    "**Input Variables:**\n",
    "- `clients` (List[FederatedClientMLP])\n",
    "- `VideoActionEnvironment` (class from Cell 45)\n",
    "\n",
    "**Output Variables:**\n",
    "- `video_clients` (List[VideoActionEnvironment])\n",
    "- `n_video_clients` (int = 5)\n",
    "\n",
    "**Code Structure:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verify prerequisites (10 lines)\n",
    "# 2. Create environments per client (20 lines)\n",
    "# 3. Print summary statistics (15 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c0dfa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Estimated Runtime:** ~2 seconds\n",
    "\n",
    "**Verification Check:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running Cell 46:\n",
    "assert len(video_clients) == 5\n",
    "assert all(isinstance(env, VideoActionEnvironment) for env in video_clients)\n",
    "print(\"âœ… Cell 46 verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28343ac0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“ Cell 47: Federated DRL Training Loop**\n",
    "\n",
    "**Purpose:** Train PPO/SAC/TD3 agents locally, aggregate via FedAvg\n",
    "\n",
    "**Dependencies:**\n",
    "- âœ… Requires Cell 46 (video_clients)\n",
    "- âœ… Requires Cell 1 (PPO, SAC, TD3 imports)\n",
    "- âœ… Requires Cell 5 (DEVICE)\n",
    "\n",
    "**Input Variables:**\n",
    "- `video_clients` (List[VideoActionEnvironment])\n",
    "- `DEVICE` (torch.device)\n",
    "\n",
    "**Output Variables:**\n",
    "- `federated_results` (Dict)\n",
    "  - `local_agents` (List[PPO/SAC/TD3])\n",
    "  - `global_policy` (nn.Module)\n",
    "  - `metrics` (Dict with rewards, losses)\n",
    "\n",
    "**Code Structure:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration (15 lines)\n",
    "# 2. Helper functions (30 lines)\n",
    "#    - federated_average_policies()\n",
    "#    - train_local_agent()\n",
    "# 3. Main training loop (60 lines)\n",
    "#    - For each round:\n",
    "#      - Local training (5k steps per client)\n",
    "#      - Collect policies\n",
    "#      - FedAvg aggregation\n",
    "#      - Log metrics\n",
    "# 4. Save results (20 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e5682",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Estimated Runtime:** ~5-10 minutes (depends on GPU/CPU)\n",
    "\n",
    "**Progress Indicators:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663326ee",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "Round 1/10 | Client 1: Training... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5000/5000 [00:45<00:00] \n",
    "           | Client 2: Training... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5000/5000 [00:42<00:00]\n",
    "           | Global Reward: 0.456 | Improvement: +0.123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884220a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“ Cell 48: DRL Ensemble & Evaluation**\n",
    "\n",
    "**Purpose:** Combine local policies into ensemble, evaluate on test set\n",
    "\n",
    "**Dependencies:**\n",
    "- âœ… Requires Cell 47 (federated_results)\n",
    "- âœ… Requires Cell 14 (X_test, y_test)\n",
    "- âœ… Requires Cell 45 (VideoActionEnvironment)\n",
    "\n",
    "**Input Variables:**\n",
    "- `federated_results['local_agents']`\n",
    "- `X_test` (np.ndarray)\n",
    "\n",
    "**Output Variables:**\n",
    "- `ensemble` (DRLEnsemble object)\n",
    "- `test_rewards` (List[float])\n",
    "- `comparison_df` (pd.DataFrame)\n",
    "\n",
    "**Code Structure:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DRLEnsemble class (40 lines)\n",
    "#    - Voting strategy\n",
    "#    - Confidence averaging\n",
    "# 2. Create test environment (10 lines)\n",
    "# 3. Evaluate each agent + ensemble (30 lines)\n",
    "# 4. Generate comparison table (20 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8e120",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Estimated Runtime:** ~1 minute\n",
    "\n",
    "**Expected Output:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda60e8d",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Agent       â”‚ Test Reward  â”‚ Avg Quality  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Client 1    â”‚ 0.542        â”‚ 0.678        â”‚\n",
    "â”‚ Client 2    â”‚ 0.489        â”‚ 0.623        â”‚\n",
    "â”‚ ...         â”‚ ...          â”‚ ...          â”‚\n",
    "â”‚ Ensemble    â”‚ 0.623 â­     â”‚ 0.734 â­     â”‚\n",
    "â”‚ Random      â”‚ 0.234        â”‚ 0.412        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e2f10",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“ Cell 49: Live Monitoring Dashboard**\n",
    "\n",
    "**Purpose:** Real-time visualization during and after training\n",
    "\n",
    "**Dependencies:**\n",
    "- âœ… Requires Cell 47 (federated_results)\n",
    "- âœ… Requires `matplotlib` (already imported)\n",
    "\n",
    "**Input Variables:**\n",
    "- `federated_results` (Dict)\n",
    "\n",
    "**Output Variables:**\n",
    "- Plots displayed inline\n",
    "- Saved to `drl_outputs_<timestamp>/`\n",
    "\n",
    "**Code Structure:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17908d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create output directory (5 lines)\n",
    "# 2. Plot reward curves (30 lines)\n",
    "# 3. Plot action distribution heatmap (25 lines)\n",
    "# 4. Plot policy convergence (25 lines)\n",
    "# 5. Save all artifacts (15 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0029da",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Estimated Runtime:** ~5 seconds\n",
    "\n",
    "**Expected Visualizations:**\n",
    "1. **4-panel dashboard**\n",
    "   - Top-left: Per-client rewards over rounds\n",
    "   - Top-right: Global policy performance\n",
    "   - Bottom-left: Action space exploration\n",
    "   - Bottom-right: FedAvg convergence\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 4: DEPENDENCY GRAPH**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd818d",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "Cell 1 (Setup)\n",
    "  â†“\n",
    "Cell 12-13 (Kinetics Features)\n",
    "  â†“\n",
    "Cell 14 (Train/Test Split)\n",
    "  â”‚\n",
    "  â”œâ†’ X_train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”œâ†’ X_test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "  â””â†’ clients[] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚\n",
    "                         â”‚   â”‚   â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚\n",
    "         â†“                   â”‚   â”‚\n",
    "    Cell 45                  â”‚   â”‚\n",
    "    VideoActionEnvironment   â”‚   â”‚\n",
    "         â†“                   â”‚   â”‚\n",
    "    Cell 46 â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜\n",
    "    Create Video Clients\n",
    "         â†“\n",
    "    Cell 47\n",
    "    Federated DRL Training\n",
    "         â†“\n",
    "    Cell 48 â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (uses X_test)\n",
    "    Ensemble Evaluation\n",
    "         â†“\n",
    "    Cell 49\n",
    "    Live Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dfca5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 5: EXECUTION STRATEGY**\n",
    "\n",
    "### **ğŸ¯ Recommended Execution Order**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fba3e",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "PHASE 1: PREPARATION (One-Time Setup)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Execute cells 1-14 (if not already run)    â”‚\n",
    "â”‚ Expected time: 2-3 minutes                 â”‚\n",
    "â”‚ Verification: Check X_train exists         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â†“\n",
    "PHASE 2: ADD NEW CELLS (Implementation)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Insert cells 45-49 after cell 44           â”‚\n",
    "â”‚ No execution yet, just adding code         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â†“\n",
    "PHASE 3: SEQUENTIAL EXECUTION\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Step 1: Run Cell 45 (environment class)    â”‚\n",
    "â”‚         Time: <1 second                    â”‚\n",
    "â”‚         Check: VideoActionEnvironment existsâ”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Step 2: Run Cell 46 (create clients)       â”‚\n",
    "â”‚         Time: ~2 seconds                   â”‚\n",
    "â”‚         Check: len(video_clients) == 5     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Step 3: Run Cell 47 (TRAINING - LONGEST)   â”‚\n",
    "â”‚         Time: 5-10 minutes                 â”‚\n",
    "â”‚         Monitor: Progress bars per round   â”‚\n",
    "â”‚         Check: federated_results exists    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Step 4: Run Cell 48 (evaluation)           â”‚\n",
    "â”‚         Time: ~1 minute                    â”‚\n",
    "â”‚         Check: Ensemble > individual agentsâ”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Step 5: Run Cell 49 (visualization)        â”‚\n",
    "â”‚         Time: ~5 seconds                   â”‚\n",
    "â”‚         Check: 4 plots displayed           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67b9d3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 6: INTEGRATION SAFEGUARDS**\n",
    "\n",
    "### **ğŸ›¡ï¸ Safety Mechanisms**\n",
    "\n",
    "**1. Namespace Isolation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cells use distinct variable names\n",
    "video_clients       # (new) vs. clients (existing)\n",
    "federated_results   # (new) vs. results (existing)\n",
    "VideoActionEnvironment  # (new) vs. FederatedAggregationEnvMLP (existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954cc82",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2. Backwards Compatibility**\n",
    "- **Zero modifications** to cells 1-44\n",
    "- Existing experiments still runnable\n",
    "- Old results preserved\n",
    "\n",
    "**3. Error Handling**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each cell includes verification\n",
    "if 'X_train' not in globals():\n",
    "    raise RuntimeError(\"Run Cell 14 first to generate data\")\n",
    "\n",
    "if len(clients) == 0:\n",
    "    raise RuntimeError(\"No clients available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae4d6e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**4. Graceful Degradation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU unavailable, use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If training too slow, reduce timesteps\n",
    "n_timesteps = 5000 if device.type == 'cuda' else 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ea81c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 7: OPTIONAL ENHANCEMENTS**\n",
    "\n",
    "### **ğŸ“¦ Shell Script Integration (Optional)**\n",
    "\n",
    "**File 1: `monitor_drl.sh`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68f3a3",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# Real-time training monitor\n",
    "\n",
    "OUTPUT_DIR=\"drl_outputs_$(date +%Y%m%d_%H%M%S)\"\n",
    "LOG_FILE=\"$OUTPUT_DIR/training_log.txt\"\n",
    "\n",
    "# Create directory\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "# Watch training progress\n",
    "watch -n 2 \"\n",
    "  clear\n",
    "  echo '=== FEDERATED DRL TRAINING MONITOR ==='\n",
    "  echo ''\n",
    "  tail -30 $LOG_FILE | grep -E 'Round|Client|Reward|Global'\n",
    "  echo ''\n",
    "  echo 'Press Ctrl+C to exit'\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501cd59",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**File 2: `plot_realtime.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f339a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live plotting utility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import pandas as pd\n",
    "\n",
    "def update_plot(frame):\n",
    "    df = pd.read_csv('drl_outputs/metrics.csv')\n",
    "    plt.clf()\n",
    "    plt.plot(df['round'], df['reward'])\n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Global Reward')\n",
    "    plt.title('Live Training Progress')\n",
    "\n",
    "ani = FuncAnimation(plt.gcf(), update_plot, interval=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc57173",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Integration:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f692784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Cell 47, add logging:\n",
    "with open(f'{output_dir}/training_log.txt', 'a') as f:\n",
    "    f.write(f\"Round {r} | Client {c} | Reward {reward:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353bfd5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 8: VALIDATION CHECKLIST**\n",
    "\n",
    "### **âœ… Pre-Implementation Verification**\n",
    "\n",
    "Before starting, ensure:\n",
    "- [ ] Cells 1-14 executed successfully\n",
    "- [ ] `X_train.shape == (140, 693)` \n",
    "- [ ] `len(clients) == 5`\n",
    "- [ ] `stable_baselines3` imported\n",
    "- [ ] `gymnasium` available\n",
    "\n",
    "### **âœ… Post-Cell Verification**\n",
    "\n",
    "**After Cell 45:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'VideoActionEnvironment' in dir()\n",
    "test_env = VideoActionEnvironment(np.random.rand(100, 693))\n",
    "assert test_env.observation_space.shape == (693,)\n",
    "assert test_env.action_space.shape == (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44577c1e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**After Cell 46:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4754c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(video_clients) == 5\n",
    "assert all(hasattr(env, 'step') for env in video_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ad695",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**After Cell 47:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9af020",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'federated_results' in globals()\n",
    "assert len(federated_results['local_agents']) == 5\n",
    "assert 'global_policy' in federated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dea7e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**After Cell 48:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'ensemble' in globals()\n",
    "assert len(test_rewards) > 0\n",
    "assert ensemble_reward > np.mean(individual_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0590d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**After Cell 49:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79051665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.path.exists('drl_outputs_<timestamp>')\n",
    "assert os.path.exists('drl_outputs_<timestamp>/reward_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1719b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 9: PERFORMANCE EXPECTATIONS**\n",
    "\n",
    "### **ğŸ“Š Resource Requirements**\n",
    "\n",
    "| Phase | CPU | GPU (MPS/CUDA) | Memory | Time |\n",
    "|-------|-----|----------------|--------|------|\n",
    "| Cell 45 | Minimal | N/A | <10MB | <1s |\n",
    "| Cell 46 | Low | N/A | ~50MB | 2s |\n",
    "| Cell 47 | High | High | 2GB | 5-10min |\n",
    "| Cell 48 | Medium | Medium | 500MB | 1min |\n",
    "| Cell 49 | Low | N/A | 100MB | 5s |\n",
    "\n",
    "### **âš¡ Optimization Tips**\n",
    "\n",
    "**For Faster Training (Cell 47):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ae7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce timesteps for testing\n",
    "n_timesteps_per_round = 2000  # instead of 5000\n",
    "\n",
    "# Use fewer federated rounds\n",
    "n_federated_rounds = 5  # instead of 10\n",
    "\n",
    "# Train only with PPO (fastest)\n",
    "agent_class = PPO  # skip SAC, TD3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acaaad2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**For Memory Constraints:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use smaller batch size\n",
    "ppo_config = {'batch_size': 32}  # instead of 64\n",
    "\n",
    "# Process clients sequentially\n",
    "for client_env in video_clients:\n",
    "    train_and_aggregate(client_env)\n",
    "    torch.cuda.empty_cache()  # Free GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79dd63e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 10: TROUBLESHOOTING GUIDE**\n",
    "\n",
    "### **ğŸ”§ Common Issues & Solutions**\n",
    "\n",
    "| Error | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| `NameError: X_train not defined` | Cell 14 not run | Execute cells 1-14 first |\n",
    "| `AssertionError: clients empty` | Client creation failed | Re-run Cell 1 |\n",
    "| `CUDA out of memory` | GPU overload | Reduce batch_size or use CPU |\n",
    "| `Environment step error` | Invalid action | Check action bounds [0-1] |\n",
    "| `Slow training (>20min)` | CPU mode | Switch to GPU or reduce timesteps |\n",
    "\n",
    "---\n",
    "\n",
    "## **PART 11: FINAL INTEGRATION DIAGRAM**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94dae0",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    COMPLETE SYSTEM ARCHITECTURE                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  EXISTING SYSTEM (Cells 1-44)                                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "â”‚  â”‚ â€¢ Kinetics data generation (693D features)          â”‚        â”‚\n",
    "â”‚  â”‚ â€¢ Federated clients with non-IID partitioning      â”‚        â”‚\n",
    "â”‚  â”‚ â€¢ FederatedAggregationEnvMLP (weight aggregation)  â”‚        â”‚\n",
    "â”‚  â”‚ â€¢ PPO/SAC/TD3 for aggregation weights              â”‚        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "â”‚                          â†“ (unchanged)                           â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  NEW VIDEO DRL SYSTEM (Cells 45-49)                            â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "â”‚  â”‚ Cell 45: VideoActionEnvironment                     â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Video streaming actions [skip, bitrate, prefetch]â”‚       â”‚\n",
    "â”‚  â”‚   â€¢ Quality-latency reward function                 â”‚        â”‚\n",
    "â”‚  â”‚                                                      â”‚        â”‚\n",
    "â”‚  â”‚ Cell 46: Video-Based Federated Clients             â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Wrap each client's data into video env          â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ 5 parallel video streaming environments         â”‚        â”‚\n",
    "â”‚  â”‚                                                      â”‚        â”‚\n",
    "â”‚  â”‚ Cell 47: Federated DRL Training                     â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Local PPO/SAC/TD3 training per client           â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ FedAvg policy aggregation                       â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ 10 federated rounds Ã— 5k timesteps              â”‚        â”‚\n",
    "â”‚  â”‚                                                      â”‚        â”‚\n",
    "â”‚  â”‚ Cell 48: Ensemble Evaluation                        â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Meta-controller combining policies              â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Test set evaluation                             â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Ensemble vs individual comparison               â”‚        â”‚\n",
    "â”‚  â”‚                                                      â”‚        â”‚\n",
    "â”‚  â”‚ Cell 49: Live Monitoring Dashboard                  â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Real-time reward curves                         â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Action distribution analysis                    â”‚        â”‚\n",
    "â”‚  â”‚   â€¢ Convergence visualization                       â”‚        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  SHARED RESOURCES                                                â”‚\n",
    "â”‚  â€¢ X_train, X_test (Kinetics features from Cell 14)            â”‚\n",
    "â”‚  â€¢ clients[] (FederatedClientMLP from Cell 1)                  â”‚\n",
    "â”‚  â€¢ DEVICE (torch.device from Cell 5)                           â”‚\n",
    "â”‚  â€¢ All SB3 algorithms (PPO, SAC, TD3 from Cell 1)             â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7e895",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ¯ APPROVAL DECISION MATRIX**\n",
    "\n",
    "### **âœ… Approve Implementation If You Want:**\n",
    "\n",
    "1. **Video-specific RL environment** with realistic streaming actions\n",
    "2. **Deep RL training** (PPO/SAC/TD3 with 5k+ timesteps per round)\n",
    "3. **Federated learning** across multiple video clients\n",
    "4. **Ensemble methods** that outperform individual agents\n",
    "5. **Live monitoring** during training\n",
    "6. **Production-ready** video streaming optimization\n",
    "\n",
    "### **âŒ Delay If You Need:**\n",
    "\n",
    "- [ ] Different action space (e.g., add \"resolution\" dimension)\n",
    "- [ ] Modified reward function (e.g., add \"bandwidth cost\")\n",
    "- [ ] Fewer/more clients (currently 5)\n",
    "- [ ] Different RL algorithms (e.g., A2C, DQN)\n",
    "- [ ] Longer training (e.g., 20 rounds instead of 10)\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“ IMPLEMENTATION CHECKLIST**\n",
    "\n",
    "Once approved, I will:\n",
    "\n",
    "- [ ] **Create Cell 45**: VideoActionEnvironment class definition\n",
    "- [ ] **Create Cell 46**: Federated video client wrapper\n",
    "- [ ] **Create Cell 47**: DRL training loop with FedAvg\n",
    "- [ ] **Create Cell 48**: Ensemble evaluation system\n",
    "- [ ] **Create Cell 49**: Live monitoring dashboard\n",
    "- [ ] **Create `monitor_drl.sh`**: Shell monitoring script (optional)\n",
    "- [ ] **Create `plot_realtime.py`**: Live plotting utility (optional)\n",
    "- [ ] **Create `training_logger.py`**: Metrics logging helper (optional)\n",
    "- [ ] **Add documentation**: Markdown cell explaining new system\n",
    "\n",
    "**Estimated Implementation Time:** 15-20 minutes  \n",
    "**Estimated First Training Run:** 5-10 minutes  \n",
    "**Total Lines of Code:** ~350 lines across 5 cells\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸš€ READY FOR APPROVAL**\n",
    "\n",
    "**Please confirm:**\n",
    "\n",
    "âœ… **Approve full implementation** â†’ I'll add all 5 cells + utilities  \n",
    "âœ… **Request modifications** â†’ Specify changes needed  \n",
    "âœ… **Need clarification** â†’ Ask any questions  \n",
    "\n",
    "**Your approval statement:** \"Approved - proceed with implementation\"\n",
    "\n",
    "Once confirmed, I'll execute the integration plan and add all cells to your notebook! ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
